# Notes (Kevin Gimpel NLP)
## 01 | What is natural language processing?
a subarea of computer science that includes problems and solutions related to human language 

### Problem categories 
#### User-Facing Applications (Everyday life) 
  - Text Classification (spam/priority/category)
  - Text Completion/Auto complete 
  - Machine Translation 
  - Personal Assistants (Siri/Alexa)
  - Speech recognition/web search 
#### Supporting Technologies (may help better design user-facing applications)
  - Part-of-Speech Tagging 
  - Constituency Parsing 
  - Dependency Parsing 
  - Semantic Role Labeling 
  - Coreference Resolution 
  - Named Entity Recognition 
#### Language Understanding Capabilities 
  - Winograd Schema Coreference Resolution 
  - Reading Comprehension Question Answering 
  - Natural Language Inference

### Solutions/A Brief History of NLP 
- classical NLP: 1960s - early 1990s 
  - linguistic theory, manually-defined rules 
  - small-scale datasets and limited experimentation 
  
- statistical NLP: late 1980s - 2013 
  - supervised machine learning with annotated datasets
  - (mostly) linear models with manually-defined features
  - linguistic knowledge used in annotation, features, etc. 
  
 - neural NLP: 2012 - present 
  - focus is on learning representations of language from large text corpora with deep neural networks 
  - less hand crafting of features/ use of linguistic structure 
  
### Why is NLP hard? 
  - Ambiguity: one form can have multiple meanings 
  - Variability: multiple forms can have the same meaning 

### Roadmap
  - words: tokenization, morphology, lexical semantics 
  - text classification 
  - language modeling and neural language models 
  - word embeddings 
  - recurrent/recursive/convolutional networks in NLP
  - sequence labeling, HMMs, dynamic programming 
  - syntax and syntactic parsing 
  - attention and transformers
  - machine translation and other NLP tasks. 